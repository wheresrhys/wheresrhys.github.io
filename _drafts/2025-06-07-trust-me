---
layout: post
title: Trust me, I'm
description: How believable is the government's pilot of using AI to increase civil service productivity?
date: 2025-06-07
draft: true
---

It's a difficult job being a train driver. Massively simplifying, for at least some of the time on at least some types of train, the job is a matter of starting the train moving, and then not doing much other than remaining alert for long periods of time. And _paying attention_ while _doing nothing_ is a very challenging activity because the mind wanders or shuts down. And the stakes are very high - drift off when you're supposed to be looking out for signals or problems on the track and you have a train crash on your hands.

I'm sure I'm not the first person to draw an analogy between this and AI. In the early days of generative AI the hallucinations were frequent and hilarious. This meant two things. Firstly, it was less effective as a productivity tool, and secondly it demanded you paid attention to its output. But these days - despite the scoffing of never-AI'ers - the output is frequently useful and correct enough to allow us to drop our guard and trust it. 

I say "correct enough" as 


2 ways AI can be wrong
- A little bit wrong, ordinary, frequent, low risk
- Massive hallucination, increasingly infrequent, but still there

convincing vs correct
- mistakes that are glaringly obvious are hidden away
- mistakes that are subtly wrong are everywhere
- culture and hype can mean convincing gets treated as correct more than it should, worsening the problem

